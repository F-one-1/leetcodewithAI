/**
 * LangChain Code Analysis Chain
 * å¤šæ­¥éª¤ä»£ç åˆ†æé“¾ï¼šé—®é¢˜åˆ†æ â†’ ä»£ç ä¼˜åŒ– â†’ ç»“æœæ ¼å¼åŒ–
 */

import { ChatAnthropic } from "@langchain/anthropic";
import { PromptTemplate } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { DEFAULT_MODEL, type ClaudeModelName } from "@/lib/ai-config";

const outputParser = new StringOutputParser();

/**
 * Create LLM instance with specified model
 */
function createLLM(modelName?: ClaudeModelName): ChatAnthropic {
  return new ChatAnthropic({
    modelName: modelName || DEFAULT_MODEL,
    temperature: 0.7,
    anthropicApiKey: process.env.ANTHROPIC_API_KEY,
  });
}

/**
 * æ­¥éª¤1: ä»£ç é—®é¢˜åˆ†æ
 * åˆ†æä»£ç çš„æ­£ç¡®æ€§ã€æ€§èƒ½ã€ä»£ç è´¨é‡ç­‰é—®é¢˜
 */
const analysisPrompt = PromptTemplate.fromTemplate(`
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä»£ç ï¼Œæ‰¾å‡ºæ‰€æœ‰é—®é¢˜ã€‚

é¢˜ç›®æè¿°ï¼š
{problemDescription}

ä»£ç ï¼š
\`\`\`javascript
{code}
\`\`\`

è¯·æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. **æ­£ç¡®æ€§é—®é¢˜**ï¼šé€»è¾‘é”™è¯¯ã€è¾¹ç•Œæ¡ä»¶å¤„ç†ã€ç‰¹æ®Šæƒ…å†µç­‰
2. **æ€§èƒ½é—®é¢˜**ï¼šæ—¶é—´å¤æ‚åº¦ã€ç©ºé—´å¤æ‚åº¦ã€å¯ä¼˜åŒ–ç‚¹
3. **ä»£ç è´¨é‡é—®é¢˜**ï¼šå¯è¯»æ€§ã€ä»£ç é£æ ¼ã€æœ€ä½³å®è·µ
4. **å…·ä½“æ”¹è¿›å»ºè®®**ï¼šé’ˆå¯¹æ¯ä¸ªé—®é¢˜æä¾›å…·ä½“çš„æ”¹è¿›æ–¹å‘

è¯·ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼è¾“å‡ºä½ çš„åˆ†æç»“æœã€‚
`);

/**
 * æ­¥éª¤2: ä»£ç ä¼˜åŒ–ç”Ÿæˆ
 * åŸºäºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–åçš„ä»£ç 
 */
const optimizationPrompt = PromptTemplate.fromTemplate(`
åŸºäºä»¥ä¸‹ä»£ç åˆ†æç»“æœï¼Œè¯·ç”Ÿæˆæ”¹è¿›åçš„å®Œæ•´ä»£ç ã€‚

åŸå§‹ä»£ç ï¼š
\`\`\`javascript
{code}
\`\`\`

åˆ†æç»“æœï¼š
{analysis}

é¢˜ç›®æè¿°ï¼š
{problemDescription}

è¦æ±‚ï¼š
1. ä¿®å¤æ‰€æœ‰å·²å‘ç°çš„æ­£ç¡®æ€§é—®é¢˜
2. ä¼˜åŒ–æ€§èƒ½ï¼ˆæ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ï¼‰
3. æå‡ä»£ç è´¨é‡å’Œå¯è¯»æ€§
4. éµå¾ª JavaScript/TypeScript æœ€ä½³å®è·µ
5. ä¿æŒå‡½æ•°ç­¾åå’Œæ¥å£ä¸å˜

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„å®Œæ•´ä»£ç ï¼Œä½¿ç”¨ \`\`\`javascript ä»£ç å—åŒ…è£¹ã€‚
ä»£ç åº”è¯¥å¯ä»¥ç›´æ¥è¿è¡Œï¼Œä¸è¦åŒ…å«é¢å¤–çš„è§£é‡Šæ–‡å­—ï¼ˆåˆ†æéƒ¨åˆ†å·²ç»åœ¨ç¬¬ä¸€æ­¥å®Œæˆï¼‰ã€‚
`);

/**
 * æ­¥éª¤3: ç»“æœæ ¼å¼åŒ–
 * å°†åˆ†æå’Œä¼˜åŒ–ç»“æœæ ¼å¼åŒ–ä¸ºæœ€ç»ˆè¾“å‡º
 */
const formatPrompt = PromptTemplate.fromTemplate(`
è¯·å°†ä»¥ä¸‹å†…å®¹æ ¼å¼åŒ–ä¸ºä¸€ä¸ªå®Œæ•´ã€æ˜“è¯»çš„åˆ†ææŠ¥å‘Šï¼š

ä»£ç åˆ†æï¼š
{analysis}

ä¼˜åŒ–åçš„ä»£ç ï¼š
{optimizedCode}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ä»£ç åˆ†æ

ï¼ˆæ­¤å¤„æ”¾ç½®åˆ†æç»“æœï¼‰

## ä¼˜åŒ–åçš„ä»£ç 

ï¼ˆæ­¤å¤„æ”¾ç½®ä¼˜åŒ–åçš„ä»£ç å—ï¼‰

ç¡®ä¿æ ¼å¼æ¸…æ™°ï¼Œä»£ç å—ä½¿ç”¨æ­£ç¡®çš„ markdown è¯­æ³•ã€‚
`);

/**
 * åˆ›å»ºä»£ç åˆ†æé“¾
 * ä½¿ç”¨ RunnableSequence å°†å¤šä¸ªæ­¥éª¤ä¸²è”èµ·æ¥
 */
export async function analyzeCodeWithChain(
  code: string,
  problemDescription?: string,
  modelName?: ClaudeModelName
): Promise<string> {
  try {
    const llm = createLLM(modelName);

    // æ„å»ºåˆ†æé“¾
    const analysisChain = RunnableSequence.from([
      analysisPrompt,
      llm,
      outputParser,
    ]);

    const optimizationChain = RunnableSequence.from([
      optimizationPrompt,
      llm,
      outputParser,
    ]);

    const formatChain = RunnableSequence.from([
      formatPrompt,
      llm,
      outputParser,
    ]);

    // æ­¥éª¤1: ä»£ç åˆ†æ
    const analysis = await analysisChain.invoke({
      code,
      problemDescription: problemDescription || "æœªæä¾›é¢˜ç›®æè¿°",
    });

    // æ­¥éª¤2: ä»£ç ä¼˜åŒ–
    const optimizedCode = await optimizationChain.invoke({
      code,
      analysis,
      problemDescription: problemDescription || "æœªæä¾›é¢˜ç›®æè¿°",
    });

    // æ­¥éª¤3: æ ¼å¼åŒ–ç»“æœ
    const formattedResult = await formatChain.invoke({
      analysis,
      optimizedCode,
    });

    return formattedResult;
  } catch (error) {
    console.error("LangChain code analysis error:", error);
    throw new Error(
      `ä»£ç åˆ†æå¤±è´¥: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`
    );
  }
}

/**
 * æµå¼ä»£ç åˆ†æé“¾ï¼ˆè¿”å› AsyncGeneratorï¼‰
 * æ”¯æŒé€æ­¥è¾“å‡ºåˆ†æç»“æœ
 */
export async function* analyzeCodeWithChainStream(
  code: string,
  problemDescription?: string,
  modelName?: ClaudeModelName
): AsyncGenerator<string, void, unknown> {
  try {
    const llm = createLLM(modelName);

    // æ­¥éª¤1: ä»£ç åˆ†æï¼ˆæµå¼ï¼‰
    yield "ğŸ” **æ­£åœ¨åˆ†æä»£ç é—®é¢˜...**\n\n";
    
    const analysisChain = RunnableSequence.from([
      analysisPrompt,
      llm,
      outputParser,
    ]);
    
    const analysisStream = await analysisChain.stream({
      code,
      problemDescription: problemDescription || "æœªæä¾›é¢˜ç›®æè¿°",
    });

    let analysis = "";
    for await (const chunk of analysisStream) {
      analysis += chunk;
      yield chunk;
    }

    yield "\n\nâœ¨ **æ­£åœ¨ç”Ÿæˆä¼˜åŒ–ä»£ç ...**\n\n";

    // æ­¥éª¤2: ä»£ç ä¼˜åŒ–ï¼ˆæµå¼ï¼‰
    const optimizationChain = RunnableSequence.from([
      optimizationPrompt,
      llm,
      outputParser,
    ]);
    
    const optimizationStream = await optimizationChain.stream({
      code,
      analysis,
      problemDescription: problemDescription || "æœªæä¾›é¢˜ç›®æè¿°",
    });

    let optimizedCode = "";
    for await (const chunk of optimizationStream) {
      optimizedCode += chunk;
      yield chunk;
    }

    // æ­¥éª¤3: æ ¼å¼åŒ–ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ï¼‰
    // å¯¹äºæµå¼è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è·³è¿‡æ ¼å¼åŒ–æ­¥éª¤ï¼Œç›´æ¥è¿”å›å‰ä¸¤æ­¥çš„ç»“æœ
    yield "\n\nâœ… **åˆ†æå®Œæˆï¼**";
  } catch (error) {
    console.error("LangChain code analysis stream error:", error);
    throw new Error(
      `ä»£ç åˆ†æå¤±è´¥: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`
    );
  }
}

